{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wasseem Dataset**\n",
    "\n",
    "7700 Tweets\n",
    "Around 16,000 tweets labeled for racism and sexism orignally. Only use it for racism as it is included in another gender dataset already.\n",
    "Unfortunately, many tweets cannot be retrieved anymore.\n",
    "Dataset from NAACL_SRW_2016.csv\n",
    "\n",
    "**IMPORTANT**: Almost no racist tweets could be retrieved\n",
    "\n",
    "```\n",
    "LABEL:\n",
    "Neutral - 0\n",
    "Racist - 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtweetLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TweetLoader\n",
      "File \u001b[0;32m~/docs/studium/ongoing/22-22/thesis/working_dir/MA_project/DatasetPreprocessing/tweetLoader.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This module contains methods to access twitter text via TWitter API.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtweepy\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m API_KEY, API_KEY_SECRET, BEARER_TOKEN, TOKEN, TOKEN_SECRET\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from prep_collection import PrepCollection as prep\n",
    "import numpy as np\n",
    "import json\n",
    "from tweetLoader import TweetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wdr_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "ds_raw_path = os.path.join(wdr_path + \"/Datasets/Racial Bias/hatespeech/NAACL_SRW_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_wasseem(wdr_path, ds_raw_path):\n",
    "    df_original = pd.read_csv(ds_raw_path, names = ['tweetID', 'label'], header= None)\n",
    "    df_r = df_original[df_original['label'] != 'sexism'] # Only use this dataset for racism\n",
    "    df_racism = df_r.drop_duplicates(subset=['tweetID'], keep='first')\n",
    "    tweet = TweetLoader()\n",
    "    tweet_ids = list(df_racism.loc[:]['tweetID'])\n",
    "    tweets = tweet.fetch_list(tweet_ids)\n",
    "    df = pd.merge(df_racism, tweets, on='tweetID', how= 'inner')\n",
    "    df['label'] = df['label'].replace(to_replace = 'racism', value= 1)\n",
    "    df['label'] = df['label'].replace(to_replace = 'none', value= 0)\n",
    "    df['text'].apply(prep.prepare_text)\n",
    "    df.to_csv(os.path.join(wdr_path + \"/Preprocessed_Datasets/034-Wasseem.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7981e52988445df9cf872d4b1a78c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135.23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_wasseem(wdr_path, ds_raw_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
